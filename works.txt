iimport sys
from PyQt6.QtWidgets import (
    QApplication, QWidget, QVBoxLayout, QPushButton,
    QTextEdit, QLineEdit, QLabel, QMessageBox
)
from gigachat_api import GigaChatClient
from local_llm import TransformersLLMClient  # –ò–º–ø–æ—Ä—Ç –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏


class MainWindow(QWidget):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("LLM –î–∏–∞–ª–æ–≥–æ–≤–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")
        self.resize(700, 600)

        self.history_gigachat = []
        self.history_local = []
        self.history_compare = []

        self.current_mode = None

        self.gigachat_client = GigaChatClient("YTBiYjgwNmYtMmUxZi00ODVhLTg0YjQtYjAzN2U5OWI5Njc4OmZkMjUzODUzLTlkNGItNDYzNy05NDU3LTJiNmExYmFkNDZiNQ==")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑
        self.local_llm_client = TransformersLLMClient()

        self.layout = QVBoxLayout(self)

        self.label_mode = QLabel("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º –∏ –Ω–∞—á–Ω–∏—Ç–µ –¥–∏–∞–ª–æ–≥")
        self.layout.addWidget(self.label_mode)

        self.btn_gigachat = QPushButton("–î–∏–∞–ª–æ–≥ —Å GigaChat (—Å–µ—Ä–≤–µ—Ä)")
        self.btn_local = QPushButton("–î–∏–∞–ª–æ–≥ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM")
        self.btn_compare = QPushButton("–î–∏–∞–ª–æ–≥ —Å –¥–≤—É–º—è –º–æ–¥–µ–ª—è–º–∏")

        self.layout.addWidget(self.btn_gigachat)
        self.layout.addWidget(self.btn_local)
        self.layout.addWidget(self.btn_compare)

        self.chat_output = QTextEdit()
        self.chat_output.setReadOnly(True)
        self.layout.addWidget(self.chat_output)

        self.input_field = QLineEdit()
        self.input_field.setPlaceholderText("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –∑–¥–µ—Å—å...")
        self.layout.addWidget(self.input_field)

        self.btn_send = QPushButton("–û—Ç–ø—Ä–∞–≤–∏—Ç—å")
        self.layout.addWidget(self.btn_send)

        self.btn_gigachat.clicked.connect(self.start_gigachat)
        self.btn_local.clicked.connect(self.start_local)
        self.btn_compare.clicked.connect(self.start_compare)
        self.btn_send.clicked.connect(self.handle_input)

    def start_gigachat(self):
        self.current_mode = "gigachat"
        self.label_mode.setText("–†–µ–∂–∏–º: –î–∏–∞–ª–æ–≥ —Å GigaChat (—Å–µ—Ä–≤–µ—Ä)")
        self.load_history()
        self.append_to_history("–ù–∞—á–∏–Ω–∞–µ–º –¥–∏–∞–ª–æ–≥ —Å GigaChat.\n", mode="gigachat")

    def start_local(self):
        self.current_mode = "local"
        self.label_mode.setText("–†–µ–∂–∏–º: –î–∏–∞–ª–æ–≥ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM")
        self.load_history()
        self.append_to_history("–ù–∞—á–∏–Ω–∞–µ–º –¥–∏–∞–ª–æ–≥ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é.\n", mode="local")
        self.local_llm_client.reset_history()

    def start_compare(self):
        self.current_mode = "compare"
        self.label_mode.setText("–†–µ–∂–∏–º: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π")
        self.load_history()
        self.append_to_history("–ù–∞—á–∏–Ω–∞–µ–º –¥–∏–∞–ª–æ–≥ —Å –¥–≤—É–º—è –º–æ–¥–µ–ª—è–º–∏.\n", mode="compare")
        self.local_llm_client.reset_history()

    def load_history(self):
        self.chat_output.clear()
        if self.current_mode == "gigachat":
            for line in self.history_gigachat:
                self.chat_output.append(line)
        elif self.current_mode == "local":
            for line in self.history_local:
                self.chat_output.append(line)
        elif self.current_mode == "compare":
            for line in self.history_compare:
                self.chat_output.append(line)

    def append_to_history(self, text: str, mode: str):
        self.chat_output.append(text)
        if mode == "gigachat":
            self.history_gigachat.append(text)
        elif mode == "local":
            self.history_local.append(text)
        elif mode == "compare":
            self.history_compare.append(text)

    def handle_input(self):
        if self.current_mode is None:
            QMessageBox.warning(self, "–û—à–∏–±–∫–∞", "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã!")
            return

        user_text = self.input_field.text().strip()
        if not user_text:
            return

        self.input_field.clear()

        if self.current_mode == "gigachat":
            self.append_to_history(f"üßë‚Äçüíª –í—ã: {user_text}", mode="gigachat")
            messages = [{"role": "system", "content": "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."}]
            for entry in self.history_gigachat:
                if entry.startswith("üßë‚Äçüíª –í—ã: "):
                    messages.append({"role": "user", "content": entry[8:]})
                elif entry.startswith("ü§ñ GigaChat: "):
                    messages.append({"role": "assistant", "content": entry[13:]})
            try:
                response = self.gigachat_client.ask(messages)
                self.append_to_history(f"ü§ñ GigaChat: {response}", mode="gigachat")
            except Exception as e:
                self.append_to_history(f"‚ùå –û—à–∏–±–∫–∞: {e}", mode="gigachat")

        elif self.current_mode == "local":
            self.append_to_history(f"üßë‚Äçüíª –í—ã: {user_text}", mode="local")
            try:
                response = self.local_llm_client.ask(user_text)
                self.append_to_history(f"ü§ñ –õ–æ–∫–∞–ª—å–Ω–∞—è LLM: {response}", mode="local")
            except Exception as e:
                self.append_to_history(f"‚ùå –û—à–∏–±–∫–∞: {e}", mode="local")

        elif self.current_mode == "compare":
            self.append_to_history(f"üßë‚Äçüíª –í—ã: {user_text}", mode="compare")
            try:
                response_giga = self.gigachat_client.ask(
                    [{"role": "system", "content": "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."}, {"role": "user", "content": user_text}]
                )
            except Exception as e:
                response_giga = f"‚ùå –û—à–∏–±–∫–∞ GigaChat: {e}"

            try:
                response_local = self.local_llm_client.ask(user_text)
            except Exception as e:
                response_local = f"‚ùå –û—à–∏–±–∫–∞ –õ–æ–∫–∞–ª—å–Ω–æ–π LLM: {e}"

            self.append_to_history(f"ü§ñ GigaChat: {response_giga}", mode="compare")
            self.append_to_history(f"ü§ñ –õ–æ–∫–∞–ª—å–Ω–∞—è LLM: {response_local}", mode="compare")



------------------------
import requests
import uuid

class GigaChatClient:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.token = None
        self.get_token()

    def get_token(self):
        url = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
        rq_uid = str(uuid.uuid4())
        headers = {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Accept': 'application/json',
            'RqUID': rq_uid,
            'Authorization': f'Basic {self.api_key}'
        }
        payload = {
            'grant_type': 'client_credentials',
            'scope': 'GIGACHAT_API_PERS'
        }

        response = requests.post(url, headers=headers, data=payload, verify=False)

        print("=== –û—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞ ===")
        print("–û—Ç–≤–µ—Ç:", response.text)
        print("=============================================")

        response.raise_for_status()
        self.token = response.json()['access_token']

    def ask(self, messages: list[dict]) -> str:
        url = "https://gigachat.devices.sberbank.ru/api/v1/chat/completions"
        rq_uid = str(uuid.uuid4())
        headers = {
            'Authorization': f'Bearer {self.token}',
            'Content-Type': 'application/json',
            'RqUID': rq_uid,
            'Accept': 'application/json'
        }
        data = {
            "model": "GigaChat:latest",  # –≠—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ—á–Ω–æ
            "messages": messages
        }
        response = requests.post(url, headers=headers, json=data, verify=False)
        response.raise_for_status()
        res_json = response.json()
        return res_json['choices'][0]['message']['content']

--------------------------------------------------
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

class TransformersLLMClient:
    def __init__(self):
        model_id = "TinyLLaMA/TinyLLaMA-1.1B-Chat-v1.0"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_id} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.device}...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(model_id).to(self.device)
        print("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

        self.system_prompt = (
            "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–º–æ—â–∏ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –Ω–∞ Spring Boot. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
        )
        self.chat_history = []

    def reset_history(self):
        self.chat_history = []

    def build_prompt(self, last_user_input: str) -> str:
        conversation = ""
        for turn in self.chat_history[-3:]:  # 3 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏—è
            conversation += f"<–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å>: {turn['user']}\n<–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç>: {turn['bot']}\n"
        conversation += f"<–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å>: {last_user_input}\n<–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç>:"
        return f"{self.system_prompt}\n{conversation}"

    def ask(self, user_input: str) -> str:
        self.chat_history.append({"user": user_input, "bot": ""})

        prompt = self.build_prompt(user_input)

        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, padding=True).to(self.device)

        with torch.no_grad():
            outputs = self.model.generate(
                input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"],
                max_new_tokens=300,
                temperature=0.7,
                top_k=50,
                top_p=0.95,
                repetition_penalty=1.2,
                no_repeat_ngram_size=3,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )

        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

        # –í—ã–¥–µ–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        if "<–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç>:" in generated_text:
            answer = generated_text.split("<–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç>:")[-1].strip()
        else:
            answer = generated_text.strip()

        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤—Å—Ç–∞–≤–∫–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        answer = answer.split("<–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å>:")[0].strip()

        self.chat_history[-1]["bot"] = answer
        return answer
